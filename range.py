import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import signal
import torch
from torch.utils.data import Dataset, DataLoader
import cv2
import librosa
import os
import glob
from tqdm import tqdm


# ==========================================
# 1. ä¿®æ”¹åçš„ Datasetï¼šåªè¿”å›åŸå§‹ Raw æ•°æ®ï¼Œä¸åšä»»ä½•å¯¹é½
# ==========================================
class RawAnalysisDataset(Dataset):
    def __init__(self, root_dir):
        self.file_pairs = self._find_files(root_dir)
        print(f"ğŸ“‚ æ‰¾åˆ° {len(self.file_pairs)} å¯¹æ ·æœ¬ç”¨äºç»Ÿè®¡åˆ†æ")

    def _find_files(self, root_dir):
        pairs = []
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘
        video_files = glob.glob(os.path.join(root_dir, "**", "*.avi"), recursive=True)
        if not video_files:
            video_files = glob.glob(os.path.join(root_dir, "**", "*.mp4"), recursive=True)

        for v_path in video_files:
            base_path = os.path.splitext(v_path)[0]
            # å°è¯•åŒ¹é…éŸ³é¢‘
            for ext in ['.flac', '.wav']:
                a_path = base_path + ext
                if os.path.exists(a_path):
                    pairs.append((v_path, a_path))
                    break
        return pairs

    def _extract_signals(self, video_path, audio_path):
        # --- è§†é¢‘æå– ---
        cap = cv2.VideoCapture(video_path)
        visual_energy = []
        while True:
            ret, frame = cap.read()
            if not ret: break
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            visual_energy.append(np.mean(gray))
        cap.release()
        visual_energy = np.array(visual_energy)

        # å½’ä¸€åŒ– (Zero-mean å¯¹äºäº’ç›¸å…³éå¸¸é‡è¦)
        if np.std(visual_energy) > 1e-5:
            visual_energy = (visual_energy - np.mean(visual_energy)) / np.std(visual_energy)

        # --- éŸ³é¢‘æå– ---
        y, sr = librosa.load(audio_path, sr=None)
        target_len = len(visual_energy)
        if target_len == 0: return None, None

        # è®¡ç®— hop_length ä»¥å¯¹é½è§†é¢‘å¸§æ•°
        samples_per_frame = int(len(y) / target_len)
        if samples_per_frame == 0: return None, None

        audio_rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=samples_per_frame, center=True)[0]

        # å¼ºåˆ¶é•¿åº¦å¯¹é½ (æˆªæ–­å¤šä½™éƒ¨åˆ†)
        min_len = min(len(visual_energy), len(audio_rms))
        visual_energy = visual_energy[:min_len]
        audio_rms = audio_rms[:min_len]

        # å½’ä¸€åŒ–
        if np.std(audio_rms) > 1e-5:
            audio_rms = (audio_rms - np.mean(audio_rms)) / np.std(audio_rms)

        return visual_energy, audio_rms

    def __len__(self):
        return len(self.file_pairs)

    def __getitem__(self, index):
        video_path, audio_path = self.file_pairs[index]
        v, a = self._extract_signals(video_path, audio_path)
        if v is None:
            return None
        return v, a, os.path.basename(video_path)


# ==========================================
# 2. æ ¸å¿ƒç»Ÿè®¡å‡½æ•°ï¼šäº’ç›¸å…³åˆ†æ (Cross-Correlation)
# ==========================================
def calculate_dataset_delays(dataset_root):
    dataset = RawAnalysisDataset(root_dir=dataset_root)
    delays = []

    print("ğŸš€ å¼€å§‹å…¨é‡æ•°æ®æ—¶å»¶ç»Ÿè®¡ (Using Cross-Correlation)...")

    # éå†æ‰€æœ‰æ•°æ®
    for i in tqdm(range(len(dataset))):
        sample = dataset[i]
        if sample is None: continue

        v_sig, a_sig, fname = sample

        # ä½¿ç”¨ scipy.signal.correlate è®¡ç®—äº’ç›¸å…³
        # mode='full' ä¼šè®¡ç®—æ‰€æœ‰å¯èƒ½çš„åç§»
        correlation = signal.correlate(v_sig, a_sig, mode='full')
        lags = signal.correlation_lags(len(v_sig), len(a_sig), mode='full')

        # æ‰¾åˆ°ç›¸å…³æ€§æœ€å¤§çš„ä½ç½®
        peak_idx = np.argmax(correlation)
        lag_frames = lags[peak_idx]

        # æ³¨æ„ï¼šlag_frames è¡¨ç¤º v ç›¸å¯¹äº a çš„ä½ç§»
        # å¦‚æœ lag æ˜¯è´Ÿæ•°ï¼Œè¯´æ˜è§†é¢‘æ¯”éŸ³é¢‘æ—©ï¼›å¦‚æœæ˜¯æ­£æ•°ï¼Œè¯´æ˜è§†é¢‘æ¯”éŸ³é¢‘æ™š (Lag)
        # æ ¹æ®ä½ çš„æè¿°ï¼Œè§†é¢‘æ˜¯ Lag (æ»å) çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬é¢„æœŸè¿™é‡Œå¤§éƒ¨åˆ†æ˜¯æ­£å€¼
        delays.append(lag_frames)

    delays = np.array(delays)

    # --- ç»Ÿè®¡åˆ†æ ---
    mean_lag = np.mean(delays)
    std_lag = np.std(delays)
    min_lag = np.min(delays)
    max_lag = np.max(delays)

    # ä½¿ç”¨ 3-Sigma å‡†åˆ™ç¡®å®šç½®ä¿¡åŒºé—´ (è¦†ç›– 99.7% çš„æ ·æœ¬)
    # æˆ–è€…ä½¿ç”¨ 2-Sigma (è¦†ç›– 95%)ï¼Œè§†æ•°æ®è„ä¹±ç¨‹åº¦è€Œå®š
    # è¿™é‡Œæˆ‘ä»¬ä¿å®ˆä¸€ç‚¹ï¼Œä½¿ç”¨ mean Â± 3*stdï¼Œå¹¶ç»“åˆ min/max

    # å»ºè®®çš„å…ˆéªŒèŒƒå›´ (å–æ•´)
    suggested_low = np.floor(mean_lag - 3 * std_lag)
    suggested_high = np.ceil(mean_lag + 3 * std_lag)

    print("\n" + "=" * 40)
    print("ğŸ“Š æ•°æ®é›†æ—¶å»¶ç»Ÿè®¡ç»“æœ (Data-Driven Prior)")
    print("=" * 40)
    print(f"æ ·æœ¬æ€»æ•°: {len(delays)}")
    print(f"å¹³å‡æ—¶å»¶ (Mean Lag): {mean_lag:.2f} å¸§")
    print(f"æ ‡å‡†å·® (Std Dev):   {std_lag:.2f} å¸§")
    print(f"æœ€å°è§‚æµ‹å€¼ (Min):   {min_lag} å¸§")
    print(f"æœ€å¤§è§‚æµ‹å€¼ (Max):   {max_lag} å¸§")
    print("-" * 40)
    print(f"ğŸ’¡ å»ºè®® CAVA è®¾ç½®èŒƒå›´ (Mean Â± 3Ïƒ):")
    print(f"   delta_low_frames  = {suggested_low:.1f}")
    print(f"   delta_high_frames = {suggested_high:.1f}")
    print("=" * 40)

    # --- å¯è§†åŒ–åˆ†å¸ƒå›¾ ---
    plt.figure(figsize=(10, 6))
    sns.histplot(delays, bins=30, kde=True, color='skyblue', edgecolor='black')
    plt.axvline(mean_lag, color='red', linestyle='--', label=f'Mean: {mean_lag:.2f}')
    plt.axvline(suggested_low, color='green', linestyle=':', label='Lower Bound (-3std)')
    plt.axvline(suggested_high, color='green', linestyle=':', label='Upper Bound (+3std)')

    plt.title(f"Distribution of Audio-Video Latency (Prior Knowledge)\nDataset: {os.path.basename(dataset_root)}")
    plt.xlabel("Lag (Frames) [Positive means Video comes after Audio]")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(alpha=0.3)

    save_path = "latency_distribution_prior.png"
    plt.savefig(save_path, dpi=300)
    print(f"ğŸ“ˆ åˆ†å¸ƒç›´æ–¹å›¾å·²ä¿å­˜è‡³: {save_path}")
    print("   (è¯·å°†æ­¤å›¾ä½œä¸ºè®ºæ–‡ä¸­çš„ Prior Knowledge ä¾æ®)")


if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„æ•°æ®è·¯å¾„
    DATA_PATH = "./intel_robotic_welding_dataset/"
    if os.path.exists(DATA_PATH):
        calculate_dataset_delays(DATA_PATH)
    else:
        print("âŒ è·¯å¾„é”™è¯¯")